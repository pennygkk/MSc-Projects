# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SdeOvwiLnC1B17N4HmEWQr0NMQG1fm1S
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import numpy as np
import pickle
import pandas as pd
import matplotlib.pyplot as plt
import glob
import re
import cv2 as cv
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder
from tensorflow.keras import datasets,layers,models
from tqdm import tqdm
from typing import List

def read_photo_path_data(path = '/content/drive/My Drive/aueb/') -> pd.DataFrame:
  """
  Reads the file paths of every jpg file in the chosen directory
  Returns a DataFrame Object
  """
  path = path +'**/*.jpg' # Includes all jpgs from all subdirectories
  file_paths = glob.glob(path, recursive = True)
  return pd.DataFrame(file_paths)


def extract_id_from_file_path(dataframe: pd.DataFrame,column_location=0) -> pd.Series:
  """
  Extracts the product id (4 digit number) contained in the file path
  Column location is used to locate the position of the path column in
  the dataframe,default in the first column (0).
  """
  regex = r"/(\d+)_"
  return dataframe.iloc[:,column_location].str.extract(regex)


def data_preproccessing(dataframe: pd.DataFrame) -> pd.DataFrame:
  """
  Extracts the ID from the file path and filters out any products
  with only one picture
  """
  dataframe.rename(columns = {0:'path'},inplace = True)
  dataframe['id'] = extract_id_from_file_path(dataframe)
  #dataframe = filter_products_with_single_photos(dataframe)
  return dataframe


def extract_label_from_dataframe(df: pd.DataFrame) -> pd.Series:
  """ Extracts the image label from path in the FIRST COLUMN.
  It is assumed that image is named as {class_label}_{counter}.jpg"""
  return df.iloc[:,0].str.split("/").str[-1].str.split("_").str[0]


def images_to_ndarray(photo_path : str, IMG_SIZE = (150,150))-> np.array:
  """
  The function reads the images supplied by 
  photo_paths parameter. The function reads an image from path,
  resizes it and turns into grayscale
  """
  nd_array = cv.imread(photo_path)
  return cv.resize(nd_array, IMG_SIZE)

# Hyper Parameters
IMG_SIZE = (150,150)
TEST_SIZE = 0.25
BATCH_SIZE = 32
EPOCHS = 15

photo_path_data = read_photo_path_data(path = '/content/drive/My Drive/aueb/compressed/') # read image paths
photo_path_data['class_label'] = extract_label_from_dataframe(photo_path_data) # extract label and assign it to column
photo_path_data.rename(columns = {0:'path'},inplace = True)
photo_path_data.head(1000)

X = [images_to_ndarray(im, IMG_SIZE = IMG_SIZE) for im in tqdm(photo_path_data['path'])]
X = np.array(X)
Y = np.array(photo_path_data['class_label'])

encoder = OrdinalEncoder()
Y = encoder.fit_transform(Y.reshape(-1,1))

X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(X,Y,test_size = TEST_SIZE, stratify = Y, random_state =42)
X_TRAIN = X_TRAIN/255
X_TEST = X_TEST/255

print(f"Number of Training Images {X_TRAIN.shape[0]}")
print(f"Number of Test Images {X_TEST.shape[0]}")

print(type(X_TRAIN))
print(type(Y_TRAIN))

# Convolution Model Building
# Custom Network Hooray
conv_model = models.Sequential()
conv_model.add(layers.Conv2D(64, (3,3), activation = 'relu', input_shape = (150,150,3)))
conv_model.add(layers.Conv2D(64, (3,3), activation = 'relu'))
conv_model.add(layers.MaxPooling2D(2,2))
conv_model.add(layers.Conv2D(64, (3,3), activation = 'relu'))
conv_model.add(layers.Conv2D(64, (3,3), activation = 'relu'))
conv_model.add(layers.MaxPooling2D(2,2))
conv_model.add(layers.Flatten())
conv_model.add(layers.Dense(4096,activation = 'relu'))
conv_model.add(layers.Dense(len(np.unique(Y_TRAIN)),activation = 'softmax'))
conv_model.summary()
conv_model.compile(optimizer = 'adam',
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),
                  metrics=['accuracy'])

from tensorflow.python.keras.callbacks import EarlyStopping
es = EarlyStopping(
    monitor   = 'accuracy', # which metric we want to use as criterion to stop training
    min_delta = 0, # Minimum change in the monitored quantity to qualify as an improvement
    patience  = 3, # we 3 epochs before stopping
    verbose   = 1, # verbosity level
    mode      = 'auto',
    restore_best_weights = True)

history = conv_model.fit(X_TRAIN,Y_TRAIN,
                         epochs = EPOCHS,
                         validation_split = 0.25,
                         callbacks = [es])

def get_predictions_from_model(nnmodel, X_TEST : np.array ) -> np.array:
  """
  Returns the predictions for the convolutional model.
  Takes as parameters the X_TEST holdout dataset
  """
  predictions = nnmodel.predict(X_TEST)
  return np.argmax(predictions, axis = 1) # Get the most probable class


def get_original_labels(transformed_labels: np.array,encoder: OrdinalEncoder) -> np.array:
  """
  The function returns the original labels (before ordinal encoding).
  """
  return encoder.inverse_transform(transformed_labels.reshape(-1,1))


def plot_image(Image_array: np.array,
                predictions_array: pd.DataFrame,
                index: int
                ) -> None:
  fig, ax = plt.subplots(figsize = (8,8))
  ax.imshow(Image_array[index])
  plt.title(f"Predicted Label {predictions_array.iloc[index,0]}") # First Columns contains correct Predictions
  plt.axis('off')

def plot_multiple_images(Image_array: np.array,
                         predictions_array: pd.DataFrame,
                         indexes: List,
                         figsize: tuple,
                         ) -> None:
  fig = plt.figure(figsize = figsize)
  ROWS = len(indexes)
  for i,index in enumerate(indexes):

    fig.add_subplot(ROWS,1,(i+1)) # show images in single row
    plt.imshow(Image_array[index])
    plt.axis('off')
    plt.title(f"Predicted Label: {predictions_array.loc[index,'Ypred']}, True Label: {predictions_array.loc[index,'Ytrue']}")

predictions = get_predictions_from_model(conv_model,X_TEST)
label_pred = get_original_labels(predictions,encoder)
label_true = get_original_labels(Y_TEST,encoder)

predictions_dataframe = pd.DataFrame({'Ytrue':label_true.reshape(-1), 'Ypred':label_pred.reshape(-1)})
correct_predictions = predictions_dataframe[predictions_dataframe['Ytrue']==predictions_dataframe['Ypred']]
false_predictions = predictions_dataframe[predictions_dataframe['Ytrue']!=predictions_dataframe['Ypred']]

correct_predictions

plot_image(X_TEST,predictions_dataframe, 920)

false_predictions_index = false_predictions.index
correct_predictions_index = correct_predictions.index
predictions_index = predictions_dataframe.index

#Plot some false predictions
plot_image(X_TEST, false_predictions, false_predictions_index[0])

plot_image(X_TEST, false_predictions, false_predictions_index[10])

plot_multiple_images(X_TEST, false_predictions, false_predictions_index[5:10], figsize = (30,30))

# Correct Predictions
plot_multiple_images(X_TEST, correct_predictions, correct_predictions_index[10:15], figsize = (30,30))

#Train VGG
from tensorflow.keras.applications import VGG16

vgg16model = VGG16(include_top = False)

#|vgg16model.summary()
for layer in vgg16model.layers:
  layer.trainable = False

