{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83a7bd8",
   "metadata": {},
   "source": [
    "# Spark Assignment\n",
    "---\n",
    "\n",
    "> *Name:* Panagiota Gkourioti <br />\n",
    "> *Student ID:* p2822109 <br />\n",
    "> *Course:* Big Data Systems and Architectures <br />\n",
    "> *Professor:* Thanasis Vergoulis <br />\n",
    "\n",
    "> Department of Management Science and Technology <br />\n",
    "> Athens University of Economics and Business <br />\n",
    "\n",
    "## Task 3\n",
    "\n",
    "For the final task, we will investigate if it is possible to train a linear regression model that could predict the “average_rating” of a book, using as input, its “language_code”, its “num_pages”, its “ratings_count”, and its\n",
    "“publication year”, using Python and Dataframes with MLlib. Specifically, the notebook will focus on:\n",
    "- preparing the feature vectors\n",
    "- preparing the training and testing datasets (70%-30%)\n",
    "- training the model\n",
    "- evaluating the accuracy of the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64fd293",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd1613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import findspark\n",
    "#findspark.init('C:\\spark\\spark-3.2.1-bin-hadoop3.2') for local installation of spark\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.context import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F \n",
    "from pyspark.sql.functions import col,when,count\n",
    "import pyspark.mllib\n",
    "import pyspark.mllib.regression\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "# import packages for linear regression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e837e",
   "metadata": {},
   "source": [
    "## Load & clean data \n",
    "\n",
    "The first step of our analysis is to import and inspect the data, ensuring that all columns have the appropriate data type and checking for missing or invalid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1edaffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data \n",
    "books = spark.read.json(\"books_5000.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd26cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data frame with the desired features\n",
    "df = books.select('average_rating', 'language_code', 'num_pages', 'ratings_count', 'publication_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e671693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('average_rating', 'string'),\n",
       " ('language_code', 'string'),\n",
       " ('num_pages', 'string'),\n",
       " ('ratings_count', 'string'),\n",
       " ('publication_year', 'string')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19ccac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to correct data types\n",
    "df = df.withColumn(\"average_rating\", df[\"average_rating\"].cast(FloatType()))\n",
    "df = df.withColumn(\"num_pages\", df[\"num_pages\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"ratings_count\", df[\"ratings_count\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2527ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('average_rating', 'float'),\n",
       " ('language_code', 'string'),\n",
       " ('num_pages', 'int'),\n",
       " ('ratings_count', 'int'),\n",
       " ('publication_year', 'string')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if corrected\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5f9e96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|publication_year|\n",
      "+----------------+\n",
      "|                |\n",
      "|             162|\n",
      "|            1945|\n",
      "|            1951|\n",
      "|            1960|\n",
      "|            1961|\n",
      "|            1962|\n",
      "|            1963|\n",
      "|            1965|\n",
      "|            1966|\n",
      "|            1968|\n",
      "|            1970|\n",
      "|            1973|\n",
      "|            1974|\n",
      "|            1975|\n",
      "|            1976|\n",
      "|            1977|\n",
      "|            1978|\n",
      "|            1979|\n",
      "|            1980|\n",
      "|            1981|\n",
      "|            1982|\n",
      "|            1983|\n",
      "|            1984|\n",
      "|            1985|\n",
      "|            1986|\n",
      "|            1987|\n",
      "|            1988|\n",
      "|            1989|\n",
      "|            1990|\n",
      "+----------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check distinct values for publication year to find any missing or invalid data\n",
    "df.select('publication_year').distinct().sort('publication_year').show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ab62cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|average_rating|language_code|num_pages|ratings_count|publication_year|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|             0|         1685|     1382|            0|            1072|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for missing/null values in all columns\n",
    "missing = df.select([count(when((col(c)=='')|col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a49b87",
   "metadata": {},
   "source": [
    "It is observed that publication year has an invalid value (162), which is assumed to be 1962, as well as many missing values. Therefore, we make the following corrections. We also replace missing values for categorical data with the word 'Unknown' and remove the rows where three values are missing at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec3b2a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace invalid value 162 in publication_year with the possibly correct one, 1962\n",
    "df = df.withColumn('publication_year', when(df.publication_year == '162', '1962').otherwise(df.publication_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84576c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace publication_year missing values with the word unknown\n",
    "df = df.withColumn('publication_year', when(df.publication_year == '', 'Unknown').otherwise(df.publication_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b0e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace language_code missing values with the word unknown\n",
    "df = df.withColumn('language_code', when(df.language_code == '', 'Unknown').otherwise(df.language_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a858440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where language_code, num_pages and publication_year are missing at the same time, because the information\n",
    "# of ratings_count exclusively would not be sufficient\n",
    "df = df.filter(~(df.num_pages.isNull()&(df.language_code == 'Unknown')&(df.publication_year == 'Unknown')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a5a288",
   "metadata": {},
   "source": [
    "Finally, we fill null values for number of pages with their average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3c8bcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|   avg(num_pages)|\n",
      "+-----------------+\n",
      "|169.7041747304396|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the average number of pages\n",
    "df.agg({'num_pages': 'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d851c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the average number of pages to replace missing values \n",
    "df = df.withColumn('num_pages', when(df.num_pages.isNull(), 170).otherwise(df.num_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a848ad39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|average_rating|language_code|num_pages|ratings_count|publication_year|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|          3.94|          fre|      170|           16|            2016|\n",
      "|          4.28|          eng|      146|           51|            2012|\n",
      "|          4.05|          eng|      170|            6|         Unknown|\n",
      "|          4.06|        en-US|      272|           51|            1997|\n",
      "|          3.44|      Unknown|      206|           46|            2007|\n",
      "|          4.15|          eng|      224|           39|            2016|\n",
      "|          3.16|      Unknown|      160|           38|            2016|\n",
      "|          3.51|      Unknown|      160|           44|            2016|\n",
      "|           4.0|      Unknown|      144|           32|            2016|\n",
      "|          4.41|          kor|      212|          133|            2014|\n",
      "|          3.16|          eng|      144|          114|            2011|\n",
      "|          4.41|          eng|      200|          149|            2012|\n",
      "|          4.39|      Unknown|      230|          152|            2012|\n",
      "|          4.31|          jpn|      157|          174|            2013|\n",
      "|          4.43|          spa|      224|           30|            2006|\n",
      "|          4.38|          zho|      176|            2|            2011|\n",
      "|           3.8|      Unknown|      192|           86|            2006|\n",
      "|          4.46|          eng|      192|            8|         Unknown|\n",
      "|          4.41|          eng|      170|           58|         Unknown|\n",
      "|          4.25|          jpn|      183|           32|            2012|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inspect the first lines after the data cleaning\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a6bc62",
   "metadata": {},
   "source": [
    "## Prepare data for training & testing\n",
    "\n",
    "The following step is to split the data into 70% as training and 30% as a testing set.  \n",
    "Moreover, here we are using a `seed` so that for each run we have exactly the same split (for reproducibility). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab21c9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3169\n",
      "1284\n"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = df.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "print(trainDF.cache().count()) # cache because of accessing training data multiple times\n",
    "\n",
    "print(testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e2b8e4",
   "metadata": {},
   "source": [
    "We can then see interesting statistics about the numerical attribute, num_pages, and the number of appearances of a categorical attribute, language_code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1926031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|         num_pages|\n",
      "+-------+------------------+\n",
      "|  count|              3169|\n",
      "|   mean|170.75039444619753|\n",
      "| stddev|100.93238554920669|\n",
      "|    min|                 4|\n",
      "|    25%|               120|\n",
      "|    50%|               170|\n",
      "|    75%|               192|\n",
      "|    max|              1192|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.select(\"num_pages\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b68357f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|language_code|count|\n",
      "+-------------+-----+\n",
      "|          fre|  151|\n",
      "|          zho|    4|\n",
      "|        en-CA|    7|\n",
      "|          fin|   31|\n",
      "|          ind|  143|\n",
      "|          nor|    7|\n",
      "|          ben|    3|\n",
      "|          pol|    6|\n",
      "|          vie|    6|\n",
      "|          por|   26|\n",
      "|          swe|   20|\n",
      "|      Unknown|  820|\n",
      "|          cze|   22|\n",
      "|          eng| 1145|\n",
      "|          jpn|  150|\n",
      "|           nl|   18|\n",
      "|          dan|    4|\n",
      "|        en-GB|   44|\n",
      "|          gre|   12|\n",
      "|          bos|    1|\n",
      "+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.groupby(\"language_code\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fcc3ea",
   "metadata": {},
   "source": [
    "## Feature preprocessing\n",
    "The next step is to manipulate the features so they are in the format MLlib requires. Since we have two categorical variables, we have to use one hot encoding, that converts categorical variables into a set of numeric variables that only take on values 0 and 1. We first use the *StringIndexer*, which converts a column of string values to a column of label indexes. \n",
    "Then, *OneHotEncoder* maps a column of category indices to a column of binary vectors, with at most one \"1\" in each row that indicates the category index for that row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57e9e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalCols = [\"language_code\", \"publication_year\"]\n",
    "\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=[x + \"Index\" for x in categoricalCols]) \n",
    "encoder = OneHotEncoder(inputCols=stringIndexer.setHandleInvalid(\"skip\").getOutputCols(), \n",
    "                        outputCols=[x + \"OHE\" for x in categoricalCols],dropLast=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd623523",
   "metadata": {},
   "source": [
    "We can also call the .fit() method to return a StringIndexerModel, which we can then use to transform the dataset.\n",
    "\n",
    "The .transform() method of StringIndexerModel returns a new DataFrame with the new columns appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f340cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+---------+-------------+----------------+------------------+---------------------+\n",
      "|average_rating|language_code|num_pages|ratings_count|publication_year|language_codeIndex|publication_yearIndex|\n",
      "+--------------+-------------+---------+-------------+----------------+------------------+---------------------+\n",
      "|           2.0|      Unknown|      144|            1|            2017|               1.0|                 10.0|\n",
      "|           2.0|          ind|      128|            1|            2010|               5.0|                  8.0|\n",
      "|          2.33|      Unknown|      368|            3|            2002|               1.0|                 16.0|\n",
      "|          2.35|      Unknown|      104|           43|            2008|               1.0|                  9.0|\n",
      "|          2.38|      Unknown|      170|            8|            1996|               1.0|                 22.0|\n",
      "|          2.53|      Unknown|      170|           30|            2017|               1.0|                 10.0|\n",
      "|          2.57|      Unknown|      208|           90|            2016|               1.0|                  4.0|\n",
      "|          2.59|      Unknown|       96|           74|            2018|               1.0|                 32.0|\n",
      "|          2.62|          eng|      128|           66|            2016|               0.0|                  4.0|\n",
      "|          2.72|          eng|       96|           24|            2013|               0.0|                  3.0|\n",
      "|          2.75|          eng|      170|           24|         Unknown|               0.0|                  0.0|\n",
      "|          2.77|      Unknown|      170|           80|            2011|               1.0|                  6.0|\n",
      "|           2.8|      Unknown|       78|            5|         Unknown|               1.0|                  0.0|\n",
      "|          2.89|          eng|      104|           57|            2015|               0.0|                  1.0|\n",
      "|          2.92|          eng|      148|           72|            2013|               0.0|                  3.0|\n",
      "|          2.92|          eng|      170|            8|         Unknown|               0.0|                  0.0|\n",
      "|          2.92|          spa|       48|            3|            2013|               2.0|                  3.0|\n",
      "|          2.95|          eng|      170|           21|            2002|               0.0|                 16.0|\n",
      "|          2.97|      Unknown|      112|           30|            2006|               1.0|                 11.0|\n",
      "|           3.0|      Unknown|       32|            2|            2012|               1.0|                  5.0|\n",
      "+--------------+-------------+---------+-------------+----------------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stringIndexerModel = stringIndexer.fit(trainDF)\n",
    "stringIndexerModel.transform(trainDF).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cac045",
   "metadata": {},
   "source": [
    "Finally, we gather all these vectors together with VectorAssembler and transform it into a single vector \n",
    "column. We will pipe this vector in our regression model, fit the data into the \n",
    "model and run a prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04b53704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This includes both the numeric columns and the one-hot encoded binary vector columns in our dataset.\n",
    "numericCols = ['num_pages', 'ratings_count']\n",
    "assemblerInputs = [c + \"OHE\" for c in categoricalCols] + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol='features').setHandleInvalid(\"skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1815068e",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "We are going to use a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6906efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\", labelCol='average_rating', regParam=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06217a77",
   "metadata": {},
   "source": [
    "## Build the pipeline\n",
    "\n",
    "In this step, we define the pipeline and then apply it to the test dataset. A `Pipeline` is an estimator. The `pipeline.fit()` method returns a `PipelineModel`, which is a transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "582dc2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline based on the stages created in previous steps.\n",
    "pipeline = Pipeline(stages=[stringIndexer, encoder, vecAssembler, lr])\n",
    "\n",
    "# Define the pipeline model.\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "# Apply the pipeline model to the test dataset to classify the respective samples.\n",
    "predDF = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7423579b",
   "metadata": {},
   "source": [
    "We can then display the predictions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0649c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+------------------+\n",
      "|            features|average_rating|        prediction|\n",
      "+--------------------+--------------+------------------+\n",
      "|(98,[1,43,96,97],...|          2.29|3.8426251582535698|\n",
      "|(98,[0,43,96,97],...|           2.5|3.9162843462801167|\n",
      "|(98,[1,53,96,97],...|          2.55|  3.87091053939996|\n",
      "|(98,[1,42,96,97],...|          2.57|3.8306982078773233|\n",
      "|(98,[1,54,96,97],...|          2.67| 3.868346771986987|\n",
      "+--------------------+--------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select(\"features\", \"average_rating\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c8740",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "To evaluate the accuracy of the model on unseen data, we use the the `RegressionEvaluator` and calculate the R Squared and Root Mean Squared Error (RMSE) metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e2163d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.0466514\n"
     ]
    }
   ],
   "source": [
    "lr_evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='average_rating', metricName='r2')\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(predDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d75fac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.446748\n"
     ]
    }
   ],
   "source": [
    "lr_evaluator2 = RegressionEvaluator(predictionCol='prediction', labelCol='average_rating', metricName='rmse')\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % lr_evaluator2.evaluate(predDF))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50db39a2",
   "metadata": {},
   "source": [
    "It appears that the model performs very poorly in terms of prediction. The R2 on test data is only 4,7%, very low, and the RMSE is 44,7%, rather high. To increase the predictive ability of the model, we could possibly add more predictors, that explain the book's average rating better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
